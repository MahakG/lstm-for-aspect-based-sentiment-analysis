{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Głęboka sieć neuronowa w aspektowej analizie wydźwięku\n",
    "\n",
    "## Tomek Korbak\n",
    "\n",
    "#### 24 maja 2016\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Problem\n",
    "\n",
    "Wytrenować klasyfikator, który dostając na wejściu zdanie języka polskiego, zwróci jego wydźwięk, to znaczy słowo wyrażające opinię."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tomek/.virtualenvs/deeplearning/local/lib/python2.7/site-packages/matplotlib/font_manager.py:273: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n",
      "  warnings.warn('Matplotlib is building the font cache using fc-list. This may take a moment.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpu0\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from itertools import chain\n",
    "from pprint import pprint\n",
    "from time import time\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.corpora.dictionary import Dictionary\n",
    "\n",
    "\n",
    "os.environ['THEANO_FLAGS'] = \"device=gpu1\"    \n",
    "import theano\n",
    "# theano.config.device = 'gpu' # Compute using GPU\n",
    "# theano.config.floatX = 'float32'\n",
    "\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Input\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.layers.core import Dense, Dropout\n",
    "from keras.layers.wrappers import TimeDistributed\n",
    "from keras.utils.visualize_util import plot\n",
    "\n",
    "np.random.seed(1337)\n",
    "\n",
    "print theano.config.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "def indices_to_one_hot_encodings(index, vector_length):\n",
    "    return [[1, 0] if i == index else [0, 1] for i in xrange(vector_length)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3906\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1431"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load and process treebank data\n",
    "\n",
    "treebank_file1 = open('json/OPTA-treebank-0.1.json')\n",
    "treebank_file2 = open('skladnica_output.json')\n",
    "treebank = chain(list(json.load(treebank_file1)), list(json.load(treebank_file2)))\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "labels = []\n",
    "for entry in treebank:\n",
    "    tree = entry['parsedSent']\n",
    "    words = []\n",
    "    sentiment = None\n",
    "    for index, node in enumerate(tree):\n",
    "        word = node.split('\\t')[1].lower()\n",
    "        words.append(word)\n",
    "        if node.split('\\t')[10] == 'S':\n",
    "            sentiment = index\n",
    "    if sentiment:\n",
    "        labels.append(words[sentiment])\n",
    "        X.append(words)\n",
    "        y.append(indices_to_one_hot_encodings(sentiment, len(words)))\n",
    "\n",
    "dataset_length = len(X)\n",
    "slicing_point = int(dataset_length*0.9)\n",
    "\n",
    "X_train_raw = X[:slicing_point]\n",
    "y_train_raw = y[:slicing_point]\n",
    "X_test_raw = X[slicing_point+1:]\n",
    "y_test_raw = y[slicing_point+1:]\n",
    "\n",
    "treebank_vocabulary = set(chain(*X))\n",
    "print len(treebank_vocabulary)\n",
    "\n",
    "X_train = X_train_raw \n",
    "y_train = labels\n",
    "\n",
    "len(X_train) + len(X_test_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raczej nie dla młodych chłopców . \n",
      "młodych \n",
      "\n",
      "spokojnie mogą konkurować z nowymi zapachami . \n",
      "konkurować \n",
      "\n",
      "mają one wyjątkowy zapach , który długo utrzymuje się na skórze . \n",
      "wyjątkowy \n",
      "\n",
      "idealnie pasuje na każdą sylwetkę . \n",
      "pasuje \n",
      "\n",
      ": ) i macie rację-to dostojny zapach , nie dla chłystków w dresach . \n",
      "dostojny \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Przykłady z danych treningowych:\n",
    "\n",
    "for index in [2, 44, 111, 384, 69]:\n",
    "    print ' '.join(X_train[index]), '\\n', y_train[index], '\\n'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Dane pochodzą z ręcznie tagowanego treebanku (korpusu anotowanego składniowo) opracowanego przez Zespół Inżynierii Lingwistycznej IPI PAN na bazie Narodowego Korpusu Języka Polskiego (Wawer, 2015).\n",
    "\n",
    "Treebank liczy około 1431 zdania. (To dość mało)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "w2v_model = Word2Vec.load('w2v_allwiki_nkjp300_200.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, u'zapachnie'), (1, u'PORADNI'), (2, u'Fitelberga'), (3, u'komedianta'), (4, u'Zaprzesta\\u0107'), (5, u'Nampo'), (6, u'Schloendorff'), (7, u'zn\\u0119kanym'), (8, u'synkopy'), (9, u'unifikacji')]\n"
     ]
    }
   ],
   "source": [
    "# Import w2v's dictionary to a bag-of-words model\n",
    "w2v_vocabulary = Dictionary()\n",
    "w2v_vocabulary.doc2bow(w2v_model.vocab.keys(), allow_update=True)\n",
    "print w2v_vocabulary.items()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# Initialize dicts for representing w2v's dictionary as indices and 200-dim vectors\n",
    "w2indx = {v: k+1 for k, v in w2v_vocabulary.items()}\n",
    "w2vec = {word: w2v_model[word] for word in w2indx.keys()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "w2v_vocabulary_size = len(w2indx) + 1\n",
    "w2v_vocabulary_dimension = len(w2vec.values()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[51615, 277138, 416148, 422622, 318134, 584324, 176240, 503788, 0]\n"
     ]
    }
   ],
   "source": [
    "def map_treebank_words_to_w2v_indices(treebank_data, w2indx):\n",
    "    treebank_data_vec = []\n",
    "    for sentence in treebank_data:\n",
    "        vectorized_sentence = []\n",
    "        for word in sentence:\n",
    "            try:\n",
    "                vectorized_sentence.append(w2indx[word])\n",
    "            except KeyError:  # words absent in w2v model will be indexed as 0s\n",
    "                vectorized_sentence.append(0)\n",
    "        treebank_data_vec.append(vectorized_sentence)\n",
    "    return treebank_data_vec \n",
    "\n",
    "X_train = map_treebank_words_to_w2v_indices(X_train_raw, w2indx)\n",
    "X_test = map_treebank_words_to_w2v_indices(X_test_raw, w2indx)\n",
    "\n",
    "print X_test[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# Define numpy weights matrix for embedding layer\n",
    "embedding_weights = np.zeros((w2v_vocabulary_size , w2v_vocabulary_dimension))\n",
    "for word, index in w2indx.items():\n",
    "    embedding_weights[index, :] = w2vec[word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# max sentence length\n",
    "max(\n",
    "    len(max(X_train, key=lambda sentence: len(sentence))),\n",
    "    len(max(X_test, key=lambda sentence: len(sentence)))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# Normalize sequences length to 40 (will be extended with 0s)\n",
    "sentence_length = 40\n",
    "X_train = sequence.pad_sequences(X_train, maxlen=sentence_length)\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=sentence_length)\n",
    "\n",
    "y_train = sequence.pad_sequences(y_train_raw, maxlen=sentence_length, value=[0, 1])\n",
    "y_test = sequence.pad_sequences(y_test_raw, maxlen=sentence_length, value=[0, 1])\n",
    "\n",
    "# print X_train[2]\n",
    "# print y_train[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "inputs = Input(shape=(sentence_length,), dtype='int32')\n",
    "\n",
    "x = Embedding(\n",
    "    input_dim=w2v_vocabulary_size, \n",
    "    output_dim=w2v_vocabulary_dimension,\n",
    "    input_length=sentence_length,\n",
    "    mask_zero=True,\n",
    "    weights=[embedding_weights]\n",
    ")(inputs)\n",
    "\n",
    "lstm_out = LSTM(200, return_sequences=True)(x)\n",
    "\n",
    "regularized_data = Dropout(0.3)(lstm_out)\n",
    "\n",
    "predictions = TimeDistributed(Dense(2, activation='sigmoid'))(regularized_data)\n",
    "\n",
    "model = Model(input=inputs, output=predictions)\n",
    "\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#Architektura sieci\n",
    "\n",
    "Zasadniczą rolę odegrają dwie warstwy, same będące pełnoprawnymi sieciami neuronowymi:\n",
    "* Warstwa embedding, mapująca słowa na wektory liczb zmiennoprzecinkowych w sposób spełniający pewne kryteria\n",
    "* Warstwa LSTM, sieć rekurencyjna szczególnie dobrze radzącą sobie z przetwarzaniem szeregów czasowych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                       Output Shape        Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_1 (InputLayer)               (None, 40)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)            (None, 40, 200)     141387200   input_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                      (None, 40, 200)     320800      embedding_1[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)                (None, 40, 200)     0           lstm_1[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "timedistributed_1 (TimeDistributed)(None, 40, 2)       402         dropout_1[0][0]                  \n",
      "====================================================================================================\n",
      "Total params: 141708402\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"342pt\" viewBox=\"0.00 0.00 222.00 342.00\" width=\"222pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 338)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"white\" points=\"-4,4 -4,-338 218,-338 218,4 -4,4\" stroke=\"none\"/>\n",
       "<!-- 140529515214416 -->\n",
       "<g class=\"node\" id=\"node1\"><title>140529515214416</title>\n",
       "<polygon fill=\"none\" points=\"41.5,-297 41.5,-333 172.5,-333 172.5,-297 41.5,-297\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"107\" y=\"-311.3\">input_1 (InputLayer)</text>\n",
       "</g>\n",
       "<!-- 140529515214544 -->\n",
       "<g class=\"node\" id=\"node2\"><title>140529515214544</title>\n",
       "<polygon fill=\"none\" points=\"23.5,-223 23.5,-259 190.5,-259 190.5,-223 23.5,-223\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"107\" y=\"-237.3\">embedding_1 (Embedding)</text>\n",
       "</g>\n",
       "<!-- 140529515214416&#45;&gt;140529515214544 -->\n",
       "<g class=\"edge\" id=\"edge1\"><title>140529515214416-&gt;140529515214544</title>\n",
       "<path d=\"M107,-296.937C107,-288.807 107,-278.876 107,-269.705\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"110.5,-269.441 107,-259.441 103.5,-269.441 110.5,-269.441\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140529223355600 -->\n",
       "<g class=\"node\" id=\"node3\"><title>140529223355600</title>\n",
       "<polygon fill=\"none\" points=\"55,-149 55,-185 159,-185 159,-149 55,-149\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"107\" y=\"-163.3\">lstm_1 (LSTM)</text>\n",
       "</g>\n",
       "<!-- 140529515214544&#45;&gt;140529223355600 -->\n",
       "<g class=\"edge\" id=\"edge2\"><title>140529515214544-&gt;140529223355600</title>\n",
       "<path d=\"M107,-222.937C107,-214.807 107,-204.876 107,-195.705\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"110.5,-195.441 107,-185.441 103.5,-195.441 110.5,-195.441\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140526808927888 -->\n",
       "<g class=\"node\" id=\"node4\"><title>140526808927888</title>\n",
       "<polygon fill=\"none\" points=\"42,-75 42,-111 172,-111 172,-75 42,-75\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"107\" y=\"-89.3\">dropout_1 (Dropout)</text>\n",
       "</g>\n",
       "<!-- 140529223355600&#45;&gt;140526808927888 -->\n",
       "<g class=\"edge\" id=\"edge3\"><title>140529223355600-&gt;140526808927888</title>\n",
       "<path d=\"M107,-148.937C107,-140.807 107,-130.876 107,-121.705\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"110.5,-121.441 107,-111.441 103.5,-121.441 110.5,-121.441\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140526799528208 -->\n",
       "<g class=\"node\" id=\"node5\"><title>140526799528208</title>\n",
       "<polygon fill=\"none\" points=\"-0.5,-1 -0.5,-37 214.5,-37 214.5,-1 -0.5,-1\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"107\" y=\"-15.3\">timedistributed_1 (TimeDistributed)</text>\n",
       "</g>\n",
       "<!-- 140526808927888&#45;&gt;140526799528208 -->\n",
       "<g class=\"edge\" id=\"edge4\"><title>140526808927888-&gt;140526799528208</title>\n",
       "<path d=\"M107,-74.937C107,-66.8072 107,-56.8761 107,-47.7047\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"110.5,-47.4406 107,-37.4407 103.5,-47.4407 110.5,-47.4406\" stroke=\"black\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import SVG\n",
    "from keras.utils.visualize_util import model_to_dot\n",
    "\n",
    "SVG(model_to_dot(model).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Word embeddings\n",
    "\n",
    "Word embedding to rodzaj statystycznego modelu językowego, który reprezentuje słowa (rzadziej złożone frazy lub całe dokumenty) jako punkty w *n*-wymiarowej przestrzeni liniowej.\n",
    "\n",
    "Bardzo pożądaną cechą tego mapowania jest to, że relacje geometryczne między punktami tej przestrzeni *odwzorowują* relacje semantyczne między kodowanymi słowami.\n",
    "\n",
    "Model taki trenuje się na bardzo dużych korpusach, każąc mu rozpoznawać wzorce współwystępowania słów. Najczęściej używanym algorytmem jest Word2Vec, opracowany przez Google (Mikolov et al., 2013a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Skorzystaliśmy z gotowego embeddingu opracowanego przez IPI PAN, wytrenowanego (z użyciem Word2Vec) na całej polskojęzycznej Wikipedii oraz trzystumilionowym zbalansowanym podkorpusie NKJP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.21601944,  0.44051808,  0.79559946, -1.68282688, -1.74369335,\n",
       "       -1.28059053, -0.39722326,  2.53322577, -1.58840847,  2.89625692,\n",
       "        0.21176136, -1.24656022, -1.851632  , -0.6131658 ,  0.09280811,\n",
       "        0.2779803 ,  1.01950109, -3.0857935 ,  1.35601997,  1.5254544 ,\n",
       "       -0.05327027, -0.82323092, -2.36823678, -0.4112888 , -1.64042878,\n",
       "       -0.00641074,  0.90136075, -1.92337966, -3.58218908, -0.88566846,\n",
       "        0.32599321, -2.20273089, -0.59569108, -1.85917747,  1.84256315,\n",
       "        1.71745014, -0.37838364,  1.85855174,  1.9673841 , -0.79426467,\n",
       "       -0.73808187,  0.3366071 , -2.58625793, -1.25763309,  0.27206179,\n",
       "       -2.31144023, -0.47351044, -1.59982193, -2.06607461, -0.86752278,\n",
       "        1.72592294, -0.69465017, -2.29019308,  1.78491342,  2.56894565,\n",
       "       -0.80506438, -0.9288221 ,  1.59838867, -0.23708618, -1.67918718,\n",
       "       -0.03720945, -1.16133761,  1.24743545,  1.21191287, -2.56924391,\n",
       "        1.95127881, -1.05310512, -1.2471137 , -0.15193334,  2.89646387,\n",
       "        0.19207561, -0.3380039 ,  1.75885475,  1.19938064, -0.52413052,\n",
       "        0.25685585,  1.414047  , -0.81787252,  0.01545324,  2.43729377,\n",
       "       -1.24133492,  1.43378913, -1.10528064,  2.2033422 ,  0.42157343,\n",
       "        1.33486164, -1.91032958, -0.05642552, -2.79640102, -0.65357786,\n",
       "        0.9766531 , -0.69810498,  0.7656948 ,  0.81560051,  1.44289052,\n",
       "       -3.42624354,  1.7126863 , -0.82548726,  1.64029348,  0.73431754,\n",
       "        2.40092421,  1.27722132,  2.08962965,  1.30449235,  0.0638469 ,\n",
       "        0.72862577,  0.67618513, -1.45907044,  1.22684562, -0.60784018,\n",
       "       -1.47931552, -0.08033065, -1.74318349,  0.77499628, -2.85728574,\n",
       "       -0.23431365, -1.01691294, -0.77199751, -1.15593803, -0.54051322,\n",
       "        2.62005734, -0.69065034, -0.89262605,  1.89626825, -3.08517241,\n",
       "        1.38132167, -1.99941468, -1.14268947, -0.59968561, -1.28886127,\n",
       "        0.42360941,  1.24560022,  0.90514952, -0.10391094, -0.26320365,\n",
       "        0.35489824, -1.05735612, -0.76474804,  0.41786137, -1.42204642,\n",
       "        2.17182851, -1.68198073, -0.42641062,  0.39401928,  1.54483426,\n",
       "       -0.05141195,  1.17525744, -1.66848934,  2.78684568,  1.33698678,\n",
       "       -1.61166167,  1.05483115,  0.11988362,  1.7951647 , -1.31195021,\n",
       "        0.15935197, -0.54916567,  0.92104959,  0.52489078, -0.98027211,\n",
       "        2.92191052, -1.14910531,  1.53513885,  0.85645872, -2.45151067,\n",
       "       -2.02326226, -1.0662744 , -1.68197167, -2.98466253, -1.63391221,\n",
       "       -0.55829096, -1.35489964,  1.69099152, -0.0917596 ,  0.61268401,\n",
       "       -0.42509523, -1.53889883, -0.77681881,  1.03906298, -0.68360895,\n",
       "       -0.75959706, -1.59627187,  2.31796312,  0.44461161,  1.00981271,\n",
       "        0.80096054,  2.06762266,  1.13360274,  0.12779287, -1.55116296,\n",
       "       -2.96953368,  0.04946666, -0.88799638, -2.01712489, -1.00320017,\n",
       "       -2.56315923, -0.38519019, -0.59912634,  0.61479992, -0.94088185], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# w modelu, który wykorzystaliśmy, słowa są reprezentowane jako\n",
    "# 200-elementowe wektory 32-bitowych liczb zmiennoprzecinkowych\n",
    "w2v_model['filozofia']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200,)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model['filozofia'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.49721665657867431"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.similarity(u'filozofia', u'inżynieria')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7536983594530452"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.similarity(u'filozofia', u'nauka')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.71805379109199341"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.similarity(u'filozofia', u'literatura')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Derrida'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# wskaż słowo niepasujące do pozostałych\n",
    "w2v_model.doesnt_match(['Kant', 'Leibniz', 'Derrida', 'Wittgenstein'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'kr\\xf3lowa', 0.7674408555030823),\n",
       " (u'cesarzowa', 0.669882595539093),\n",
       " (u'ksi\\u0119\\u017cniczka', 0.667689323425293),\n",
       " (u'ksi\\u0119\\u017cna', 0.6258757710456848),\n",
       " (u'caryca', 0.6103663444519043),\n",
       " (u'dama', 0.6032381057739258),\n",
       " (u'imperatorowa', 0.6007956862449646),\n",
       " (u'dynastia', 0.6004920601844788),\n",
       " (u'hrabina', 0.573236882686615),\n",
       " (u'elekcja', 0.5710059404373169)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Kobieta + król - mężczyzna = królowa\n",
    "# Medialny przykład z (Mikolov et al., 2013b)\n",
    "w2v_model.most_similar(positive=[u'kobieta', u'król'], negative=[u'mężczyzna'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'Kulturalna', 0.5529330968856812),\n",
       " (u'Warszawa', 0.539720356464386),\n",
       " ('Berlin', 0.52457195520401),\n",
       " (u'Almanach', 0.5210937261581421),\n",
       " (u'Ekspres', 0.5202639698982239),\n",
       " (u'Literacki', 0.5191857814788818),\n",
       " (u'Wroc\\u0142aw', 0.5109399557113647),\n",
       " (u'Krak\\xf3w', 0.5104151964187622),\n",
       " (u'Londyn', 0.5102135539054871),\n",
       " (u'Energoprojekt', 0.5069946050643921)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Paryż - Francja + Polska = Warszawa\n",
    "w2v_model.most_similar(positive=[u'Paryż', u'Polska'], negative=[u'Francja'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'malarstwo', 0.3539747893810272),\n",
       " (u'literatur\\u0119', 0.35328927636146545),\n",
       " (u'humanistyczne', 0.3381263017654419),\n",
       " (u'buddyzm', 0.3335428237915039),\n",
       " (u'sport', 0.3307268023490906),\n",
       " (u'nauki', 0.32819390296936035),\n",
       " (u'astronomi\\u0105', 0.3244932293891907),\n",
       " (u'filozoficzne', 0.32311704754829407),\n",
       " (u'krajoznawstwo', 0.3222176730632782),\n",
       " (u'tw\\xf3rczo\\u015b\\u0107', 0.3211820423603058)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# filozofia - logika = literatura\n",
    "w2v_model.most_similar(positive=[u'filozofia',], negative=[u'logika'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'wiedza', 0.49253422021865845),\n",
       " (u'praca', 0.4822917580604553),\n",
       " (u'nauka', 0.4789964258670807),\n",
       " (u'praktyka', 0.4766387343406677),\n",
       " (u'koncepcja', 0.47612860798835754),\n",
       " (u'teoria', 0.4726237952709198),\n",
       " (u'pisanina', 0.46762341260910034),\n",
       " (u'wizja', 0.46703991293907166),\n",
       " (u'problematyka', 0.4616868495941162),\n",
       " (u'inicjatywa', 0.45774880051612854)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# filozofia - postmodernizm = wiedza\n",
    "w2v_model.most_similar(positive=[u'filozofia',], negative=[u'postmodernizm'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Różnica wektorów „Paryż” i „Francja” reprezentuje pojęcie STOLICA?\n",
    "<img src=\"capitals.png\">\n",
    "\n",
    "<center>Rzut (przez analizę składowych głównych) 1000-wymiarowego word embeddingu dla języka angielskiego. Przedruk z (Mikolov et al., 2013).</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Warstwa LSTM\n",
    "\n",
    "Long Short-Term Memory to bardzo popularna architektura rekurencyjnych sieci neuronowych, często używana do etykietowania lub predykcji szeregów czasowych (Hochreiter i Schmidhuber, 1997).\n",
    "\n",
    "LSTM, dzięki połączeniom rekurencyjnym, utrzymuje coś w rodzaju *pamięci roboczej*, którą w każdej iteracji może aktualizować.\n",
    "\n",
    "Zdolność do zapamiętywania odległych zależności (*long-term dependecies*), takich jak związek zgody, czyni ją najpopularniejszą architekturą do przetwarzania języka naturalnego."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Przetwarzanie danych sekwencyjnych przez rekurencyjną sieć neuronową\n",
    "\n",
    "Przy *n*-tej iteracji sieć dostaje na wejście *n*-ty element ciągu uczącego oraz pewien wektor zapamiętany z (*n-1*)-tej iteracji.\n",
    "\n",
    "<img src=\"RNN-unrolled.png\"> <br />\n",
    "\n",
    "<center><small>Przedruk z http://colah.github.io/posts/2015-08-Understanding-LSTMs/</small></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Przy każdej iteracji sieć decyduje, która informacje usunąć z pamięci roboczej, a które od niej dodać. Reguły aktualizacji pamięci roboczej (jako macierz wag połączeń) także podlegają uczeniu.\n",
    "\n",
    "<img src=\"LSTM3-chain.png\"> <br />\n",
    "\n",
    "<center><small>Przedruk z http://colah.github.io/posts/2015-08-Understanding-LSTMs/</small></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Przepływ danych przez sieć\n",
    "\n",
    "<img align=\"right\" src=\"model.png\">\n",
    "\n",
    "Przykład | Opis\n",
    "--- | ---\n",
    "```'Kotek'``` | token\n",
    " 89762 | indeks tokenu w modelu w2v\n",
    "```array([ 0.21601944, ..., dtype=float32)``` | 200-elementowy wektor\n",
    " ...kolejne wektory... | dalsze etapy przetwarzania\n",
    " ```[0.9111, 0.0999]``` | zero-jedynkowy rozkład prawdopodobieństwa przynależności do klasy wydźwięk lub nie-wydźwięk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1288 samples, validate on 143 samples\n",
      "Epoch 1/5\n",
      "310s - loss: 0.2090 - acc: 0.9761 - val_loss: 0.2701 - val_acc: 0.9680\n",
      "Epoch 2/5\n",
      "329s - loss: 0.0860 - acc: 0.9872 - val_loss: 0.2604 - val_acc: 0.9699\n",
      "Epoch 3/5\n",
      "344s - loss: 0.0412 - acc: 0.9905 - val_loss: 0.2790 - val_acc: 0.9678\n",
      "Epoch 4/5\n",
      "358s - loss: 0.0233 - acc: 0.9917 - val_loss: 0.2874 - val_acc: 0.9657\n",
      "Epoch 5/5\n",
      "378s - loss: 0.0171 - acc: 0.9921 - val_loss: 0.3155 - val_acc: 0.9652\n"
     ]
    }
   ],
   "source": [
    "batch_size = 5\n",
    "n_epoch = 5\n",
    "\n",
    "\n",
    "hist = model.fit(X_train, y_train, batch_size=batch_size, nb_epoch=n_epoch, \n",
    "                 validation_data=(X_test, y_test), verbose=2)\n",
    "\n",
    "# epochs = 10\n",
    "\n",
    "# for i in range(epochs):\n",
    "#     print('Epoch', i, '/', epochs)\n",
    "#     model.fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "# Uczenie\n",
    "\n",
    "<img src=\"plot.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# plt.rcParams['figure.figsize'] = (10,10)\n",
    "\n",
    "# axes = plt.gca()\n",
    "# x_min = hist.epoch[0]\n",
    "# x_max = hist.epoch[-1]+1\n",
    "# axes.set_xlim([x_min,x_max])\n",
    "\n",
    "# plt.scatter(hist.epoch, hist.history['acc'], color='r')\n",
    "# plt.plot(hist.history['acc'], color='r', label=u'Trafność mierzona na zbiorze treningowym')\n",
    "# plt.scatter(hist.epoch, hist.history['val_acc'], color='c')\n",
    "# plt.plot(hist.history['val_acc'], color='c', label=u'Trafność mierzona na zbiorze walidacyjnym')\n",
    "# plt.xlabel('epoki')\n",
    "# plt.ylabel(u'Trafność')\n",
    "# plt.title(u'Trafność w kolejnych epokach')\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Ocena trafności\n",
    "\n",
    "Oceny trafności dokonano na 143-zdaniowym podzbiorze treebanku, niewykorzystanym podczas treningu.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.965209802548\n"
     ]
    }
   ],
   "source": [
    "# Ułamek poprawnie sklasyfikowanych tokenów\n",
    "score, acc = model.evaluate(X_test, y_test, batch_size=batch_size, verbose=0)\n",
    "print 'Test accuracy:', acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s     \n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(X_test, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "def change_encoding_word(word):\n",
    "    return 1 if list(np.rint(word)) == [1, 0] else 0\n",
    "\n",
    "def change_encoding(one_hot_encoded_sentence):\n",
    "    # Switch from ndarray([[0.88, 0.11], [0.34, 0.98]]) encoding to [1, 0] encoding \n",
    "    # and finally index number\n",
    "    normalized_sentence = []\n",
    "    for word in one_hot_encoded_sentence:\n",
    "        normalized_sentence.append(change_encoding_word(word))\n",
    "    return normalized_sentence\n",
    "\n",
    "def accurately_evaluated_samples():\n",
    "    total_accuracy = 0\n",
    "    for n, sentence in enumerate(predictions):\n",
    "        index_of_sentiment = np.argmax(change_encoding(sentence))\n",
    "#         print change_encoding_word(y_test[n][index_of_sentiment])\n",
    "        total_accuracy += change_encoding_word(y_test[n][index_of_sentiment])\n",
    "    return total_accuracy\n",
    "    \n",
    "      \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Wartość bardzo przeszacowana ze względu na nierównomierną częśtość występowania klas (1:39 dla wydźwięku vs nie-wydźwięku)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Bardziej adekwatna metryka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.34965034965034963"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ułamek tokenów-wydźwięków, które poprawnie rozpoznano jako wydźwięki\n",
    "float(accurately_evaluated_samples())/y_test.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Nie wygląda imponująco, ale...\n",
    "* Przy zgadywaniu trafność wynosiłaby 0,0625% (= $1/40^2$),\n",
    "* Maksymalny możliwy wynik oscyluje wokół 80%, bo taka jest średnia zgodność ludzkich anotacji (Ogneva, 2012)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Plany na przyszłość\n",
    "\n",
    "* Zwiększenie trafności przewidywań\n",
    "    * Dodanie drugiej (i kolejnych) warstwy LSTM powinno umożliwić budowanie przez sieć bardziej złożonych hierarchicznych reprezentacji zależności w zdaniach\n",
    "    * Wydłużenie treningu sieci przy wykonywaniu obliczeń przez GPU lub szybszą maszynę\n",
    "    \n",
    "* Rozszerzenie problemu o inne trenowanie innych klasyfikatorów:\n",
    "    * Ekstrakcja obiektów, których aspektom przypisywany jest wydźwięk\n",
    "    * Klasyfikowanie wydźwięku (pozytywny lub negatywny) dla pary `<obiekt, wydźwięk>`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Kod źródłowy\n",
    "\n",
    "Repozytorium jest dostępne pod adresem: https://github.com/tomekkorbak/lstm-for-aspect-based-sentiment-analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Użyte oprogramowanie\n",
    "\n",
    "* Keras (wysokopoziomowy wrapper na Theano)\n",
    "* Theano (implementacja sieci i jej treningu)\n",
    "* Scikit-learn (walidacja)\n",
    "* Gensim (model językowy Word2Vec)\n",
    "* Numpy (pomocnicze obliczenia numeryczne)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Bibliografia\n",
    "1. Hochreiter, S. i Schmidhuber, J, (1997). Long Short-Term Memory, „Neural Computation”, 9 (8), ss. 1735-1780.\n",
    "2. Mikolov, T.,  Sutskever, I.,  Chen, K., Corrado, G., i Dean, J. (2013a). Distributed Representations of Words and Phrases and their Compositionality. „Advances in Neural Information Processing Systems 26”, ss. 3111-3119.\n",
    "3. Mikolov, T., Chen, K., Corrado, G. i Dean, J. (2013b). Efficient estimation of word representations in vector space. \n",
    "4. Ogneva, M. (2012). How Companies Can Use Sentiment Analysis to Improve Their Business\n",
    "5. Wawer, A. (2015). Towards Domain-Independent Opinion Target Extraction. „IEEE 15th International Conference on Data Mining Workshops”, ss. 1326-1331.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# <center>Dziękuję za uwagę</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'acc': [0.97610637001832079,\n",
       "  0.98715061578691377,\n",
       "  0.99050852938653522,\n",
       "  0.9916537196277091,\n",
       "  0.99210014624625265],\n",
       " 'loss': [0.20902245508807693,\n",
       "  0.08603155619380938,\n",
       "  0.041203499367635593,\n",
       "  0.023266617574053673,\n",
       "  0.017146764686461306],\n",
       " 'val_acc': [0.96800700267711715,\n",
       "  0.96993008193436203,\n",
       "  0.96783217975309677,\n",
       "  0.96573427965591008,\n",
       "  0.96520980254753486],\n",
       " 'val_loss': [0.2701167392355579,\n",
       "  0.26044547015970404,\n",
       "  0.2789940552694814,\n",
       "  0.28738793543168717,\n",
       "  0.31553373897409104]}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hist.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s     \n",
      "('Test score:', 0.31553373897409104)\n",
      "('Test accuracy:', 0.96520980254753486)\n"
     ]
    }
   ],
   "source": [
    "score, acc = model.evaluate(X_test, y_test,\n",
    "                            batch_size=batch_size)\n",
    "print('Test score:', score)\n",
    "print('Test accuracy:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
