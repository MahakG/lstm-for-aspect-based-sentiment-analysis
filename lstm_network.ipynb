{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from itertools import chain\n",
    "from pprint import pprint\n",
    "from time import time\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.corpora.dictionary import Dictionary\n",
    "\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Input\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.layers.core import Dense, Dropout\n",
    "from keras.layers.wrappers import TimeDistributed\n",
    "np.random.seed(1337)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def indices_to_one_hot_encodings(index, vector_length):\n",
    "    return [[1, 0] if i == index else [0, 1] for i in xrange(vector_length)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3906\n"
     ]
    }
   ],
   "source": [
    "# Load and process treebank data\n",
    "\n",
    "treebank_file1 = open('json/OPTA-treebank-0.1.json')\n",
    "treebank_file2 = open('skladnica_output.json')\n",
    "treebank = chain(list(json.load(treebank_file1)), list(json.load(treebank_file2)))\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "for entry in treebank:\n",
    "    tree = entry['parsedSent']\n",
    "    words = []\n",
    "    sentiment = None\n",
    "    for index, node in enumerate(tree):\n",
    "        word = node.split('\\t')[1].lower()\n",
    "        words.append(word)\n",
    "        if node.split('\\t')[10] == 'S':\n",
    "            sentiment = index\n",
    "    if sentiment:\n",
    "        X.append(words)\n",
    "        y.append(indices_to_one_hot_encodings(sentiment, len(words)))\n",
    "\n",
    "dataset_length = len(X)\n",
    "slicing_point = int(dataset_length*0.9)\n",
    "\n",
    "X_train_raw = X[:slicing_point]\n",
    "y_train_raw = y[:slicing_point]\n",
    "X_test_raw = X[slicing_point+1:]\n",
    "y_test_raw = y[slicing_point+1:]\n",
    "\n",
    "treebank_vocabulary = set(chain(*X))\n",
    "print len(treebank_vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'raczej', u'nie', u'dla', u'm\\u0142odych', u'ch\\u0142opc\\xf3w', u'.']\n",
      "[[0, 1], [0, 1], [0, 1], [1, 0], [0, 1], [0, 1]]\n"
     ]
    }
   ],
   "source": [
    "print X_train_raw[2]\n",
    "print y_train_raw[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w2v_model = Word2Vec.load('w2v_allwiki_nkjp300_200.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, u'zapachnie'), (1, u'PORADNI'), (2, u'Fitelberga'), (3, u'komedianta'), (4, u'Zaprzesta\\u0107'), (5, u'Nampo'), (6, u'Schloendorff'), (7, u'zn\\u0119kanym'), (8, u'synkopy'), (9, u'unifikacji')]\n"
     ]
    }
   ],
   "source": [
    "# Import w2v's dictionary to a bag-of-words model\n",
    "w2v_vocabulary = Dictionary()\n",
    "w2v_vocabulary.doc2bow(w2v_model.vocab.keys(), allow_update=True)\n",
    "print w2v_vocabulary.items()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Initialize dicts for representing w2v's dictionary as indices and 200-dim vectors\n",
    "w2indx = {v: k+1 for k, v in w2v_vocabulary.items()}\n",
    "w2vec = {word: w2v_model[word] for word in w2indx.keys()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "w2v_vocabulary_size = len(w2indx) + 1\n",
    "w2v_vocabulary_dimension = len(w2vec.values()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[51615, 277138, 416148, 422622, 318134, 584324, 176240, 503788, 0]\n"
     ]
    }
   ],
   "source": [
    "def map_treebank_words_to_w2v_indices(treebank_data, w2indx):\n",
    "    treebank_data_vec = []\n",
    "    for sentence in treebank_data:\n",
    "        vectorized_sentence = []\n",
    "        for word in sentence:\n",
    "            try:\n",
    "                vectorized_sentence.append(w2indx[word])\n",
    "            except KeyError:  # words absent in w2v model will be indexed as 0s\n",
    "                vectorized_sentence.append(0)\n",
    "        treebank_data_vec.append(vectorized_sentence)\n",
    "    return treebank_data_vec \n",
    "\n",
    "X_train = map_treebank_words_to_w2v_indices(X_train_raw, w2indx)\n",
    "X_test = map_treebank_words_to_w2v_indices(X_test_raw, w2indx)\n",
    "\n",
    "print X_test[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define numpy weights matrix for embedding layer\n",
    "embedding_weights = np.zeros((w2v_vocabulary_size , w2v_vocabulary_dimension))\n",
    "for word, index in w2indx.items():\n",
    "    embedding_weights[index, :] = w2vec[word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# max sentence length\n",
    "max(\n",
    "    len(max(X_train, key=lambda sentence: len(sentence))),\n",
    "    len(max(X_test, key=lambda sentence: len(sentence)))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[     0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0 580109 431241 193758 639684 453311      0]\n",
      "[[0 1]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [1 0]\n",
      " [0 1]\n",
      " [0 1]]\n"
     ]
    }
   ],
   "source": [
    "# Normalize sequences length to 40 (will be extended with 0s)\n",
    "sentence_length = 40\n",
    "X_train = sequence.pad_sequences(X_train, maxlen=sentence_length)\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=sentence_length)\n",
    "\n",
    "y_train = sequence.pad_sequences(y_train_raw, maxlen=sentence_length, value=[0, 1])\n",
    "y_test = sequence.pad_sequences(y_test_raw, maxlen=sentence_length, value=[0, 1])\n",
    "\n",
    "print X_train[2]\n",
    "print y_train[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "inputs = Input(shape=(sentence_length,), dtype='int32')\n",
    "\n",
    "x = Embedding(\n",
    "    input_dim=w2v_vocabulary_size, \n",
    "    output_dim=w2v_vocabulary_dimension,\n",
    "    input_length=sentence_length,\n",
    "    mask_zero=True,\n",
    "    weights=[embedding_weights]\n",
    ")(inputs)\n",
    "\n",
    "lstm_out = LSTM(200, return_sequences=True)(x)\n",
    "\n",
    "regularized_data = Dropout(0.3)(lstm_out)\n",
    "\n",
    "predictions = TimeDistributed(Dense(2, activation='sigmoid'))(regularized_data)\n",
    "\n",
    "model = Model(input=inputs, output=predictions)\n",
    "\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                       Output Shape        Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_1 (InputLayer)               (None, 40)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)            (None, 40, 200)     141387200   input_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                      (None, 40, 200)     320800      embedding_1[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)                (None, 40, 200)     0           lstm_1[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "timedistributed_1 (TimeDistributed)(None, 40, 2)       402         dropout_1[0][0]                  \n",
      "====================================================================================================\n",
      "Total params: 141708402\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1288 samples, validate on 143 samples\n",
      "Epoch 1/4\n",
      "37s - loss: 0.3807 - acc: 0.9374 - val_loss: 0.3047 - val_acc: 0.9717\n",
      "Epoch 2/4\n",
      "37s - loss: 0.2202 - acc: 0.9788 - val_loss: 0.2642 - val_acc: 0.9722\n",
      "Epoch 3/4\n",
      "35s - loss: 0.1542 - acc: 0.9825 - val_loss: 0.2567 - val_acc: 0.9706\n",
      "Epoch 4/4\n",
      "35s - loss: 0.1115 - acc: 0.9859 - val_loss: 0.2557 - val_acc: 0.9710\n"
     ]
    }
   ],
   "source": [
    "batch_size = 50\n",
    "n_epoch = 4\n",
    "\n",
    "\n",
    "hist = model.fit(X_train, y_train, batch_size=batch_size, nb_epoch=n_epoch, \n",
    "                 validation_data=(X_test, y_test), verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 0s     \n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(X_test[:100], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.49302822  0.50694001] [0 1]\n",
      "[ 0.49302822  0.50694001] [0 1]\n",
      "[ 0.49302822  0.50694001] [0 1]\n",
      "[ 0.49302822  0.50694001] [0 1]\n",
      "[ 0.49302822  0.50694001] [0 1]\n",
      "[ 0.49302822  0.50694001] [0 1]\n",
      "[ 0.49302822  0.50694001] [0 1]\n",
      "[ 0.49302822  0.50694001] [0 1]\n",
      "[ 0.49302822  0.50694001] [0 1]\n",
      "[ 0.49302822  0.50694001] [0 1]\n",
      "[ 0.49302822  0.50694001] [0 1]\n",
      "[ 0.49302822  0.50694001] [0 1]\n",
      "[ 0.49302822  0.50694001] [0 1]\n",
      "[ 0.49302822  0.50694001] [0 1]\n",
      "[ 0.49302822  0.50694001] [0 1]\n",
      "[ 0.49302822  0.50694001] [0 1]\n",
      "[ 0.49302822  0.50694001] [0 1]\n",
      "[ 0.49302822  0.50694001] [0 1]\n",
      "[ 0.49302822  0.50694001] [0 1]\n",
      "[ 0.49302822  0.50694001] [0 1]\n",
      "[ 0.49302822  0.50694001] [0 1]\n",
      "[ 0.49302822  0.50694001] [0 1]\n",
      "[ 0.49302822  0.50694001] [0 1]\n",
      "[ 0.49302822  0.50694001] [0 1]\n",
      "[ 0.49302822  0.50694001] [0 1]\n",
      "[ 0.49302822  0.50694001] [0 1]\n",
      "[ 0.49302822  0.50694001] [0 1]\n",
      "[ 0.49302822  0.50694001] [0 1]\n",
      "[ 0.49302822  0.50694001] [0 1]\n",
      "[ 0.49302822  0.50694001] [0 1]\n",
      "[ 0.49302822  0.50694001] [0 1]\n",
      "[ 0.49302822  0.50694001] [0 1]\n",
      "[ 0.49302822  0.50694001] [0 1]\n",
      "[ 0.00450811  0.9966414 ] [0 1]\n",
      "[ 0.06815407  0.90193081] [0 1]\n",
      "[ 0.00419634  0.99443793] [0 1]\n",
      "[ 0.00419634  0.99443793] [0 1]\n",
      "[ 0.05303508  0.91800994] [0 1]\n",
      "[ 0.00220338  0.99682796] [1 0]\n",
      "[ 0.00220338  0.99682796] [0 1]\n"
     ]
    }
   ],
   "source": [
    "pred = predictions[3]\n",
    "for i in range(len(pred)):\n",
    "    print pred[i], y_test[3][i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
